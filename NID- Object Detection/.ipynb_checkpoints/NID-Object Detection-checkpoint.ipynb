{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag4vBc_XjXRf"
   },
   "source": [
    "# Open In Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIfh7bcrjXFB"
   },
   "source": [
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HelloJahid/Project-NID/blob/main/NID-%20Object%20Detection/NID-Object%20Detection.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1viLEDR4p1Nh"
   },
   "source": [
    "# Detecto \n",
    "Detecto is a Python package that allows you to build fully-functioning computer vision and object detection models.\n",
    "\n",
    "Detecto is a Python library built on top of PyTorch that simplifies the process of building object detection models. The library acts as a lightweight package that reduces the amount of code needed to initialize models, apply transfer learning on custom datasets, and run inference on images and videos.\n",
    "\n",
    "Detecto’s Model class is built on a Faster R-CNN ResNet-50 FPN architecture from torchvision’s models subpackage, which is pre-trained on the COCO 2017 dataset. By default, it can detect about 80 different objects such as fruits, animals, vehicles, kitchen appliances, and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_N53zxDtLcI"
   },
   "source": [
    "First, mount your drive to give the notebook access to your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "akEJID_wnMTc",
    "outputId": "33350752-cbf6-474d-dc26-43dcc596c39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tfKRhZYlSZ7v",
    "outputId": "094b9971-b87d-4280-ed29-90928e7c48ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data.zip  peoples.zip\n"
     ]
    }
   ],
   "source": [
    "! dir '/content/drive/My Drive/Colab Notebooks/Object Detection/Dectecto/own/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MdDGCbSNSbAF",
    "outputId": "80730599-cb5f-4b0b-ea42-2416bb6fab50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_filepath = '/content/drive/My Drive/Colab Notebooks/Object Detection/Dectecto/own/Data/peoples.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(zip_filepath, 'r')\n",
    "file = zip_ref.extractall(\"./Data\")\n",
    "zip_ref.close()\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "cOwrGwVRSg1c",
    "outputId": "fbdafa95-ae4d-4cc7-e6fd-b070dee1cf16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\ttrain_labels  val_labels\n"
     ]
    }
   ],
   "source": [
    "! dir  '/content/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6Re86sdoSgx7",
    "outputId": "513521cc-8401-401d-80cd-7c31e12fd1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data  drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbbfT8MsSgtL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-dkmBIPSgpT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXg6coT0Sgld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "M3-sRIuiuYDh",
    "outputId": "f08d10e3-20c8-44e7-8b1c-c9a022e5cd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting detecto\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/7f/f00c24877398ada1e56a401bcb8e6fa6ced476ddb2c73f310b0b0e89495d/detecto-1.1.4-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detecto) (3.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from detecto) (1.0.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from detecto) (0.6.1+cu101)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from detecto) (1.5.1+cu101)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from detecto) (4.1.2.30)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->detecto) (2018.9)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->detecto) (7.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->detecto) (0.16.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->detecto) (1.12.0)\n",
      "Installing collected packages: detecto\n",
      "Successfully installed detecto-1.1.4\n"
     ]
    }
   ],
   "source": [
    "# Note: if it states you must restart the runtime in order to use a\n",
    "# newly installed version of a package, you do NOT need to do this. \n",
    "!pip install detecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peLysju5vOgA"
   },
   "source": [
    "Import everything we need in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgJi8407uowH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from detecto import core, utils, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5UqkoIevXSX"
   },
   "source": [
    "To check that everything's working, we can try reading in one of the images from our images folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmjpizSMvJLn"
   },
   "outputs": [],
   "source": [
    "# image = utils.read_image('/content/Data/peoples/images/DSC_0006.JPG')\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCEC_0EQwLDf"
   },
   "source": [
    "How cute! Now, we're ready to create our dataset and train our model. However, before doing so, it's a bit slow working with hundreds of individual XML label files, so we should convert them into a single CSV file to save time later down the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_Pnr8quRv8v7",
    "outputId": "ed10185e-b4f2-41cc-92e2-929b031615a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSC_0003.JPG</td>\n",
       "      <td>3000</td>\n",
       "      <td>4496</td>\n",
       "      <td>h</td>\n",
       "      <td>1024</td>\n",
       "      <td>297</td>\n",
       "      <td>2129</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSC_0114.JPG</td>\n",
       "      <td>4496</td>\n",
       "      <td>3000</td>\n",
       "      <td>j</td>\n",
       "      <td>2007</td>\n",
       "      <td>120</td>\n",
       "      <td>2513</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_20200131_124203.jpg</td>\n",
       "      <td>3120</td>\n",
       "      <td>4160</td>\n",
       "      <td>h</td>\n",
       "      <td>1359</td>\n",
       "      <td>1349</td>\n",
       "      <td>1820</td>\n",
       "      <td>1782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_20200204_091655.jpg</td>\n",
       "      <td>4160</td>\n",
       "      <td>3120</td>\n",
       "      <td>j</td>\n",
       "      <td>1674</td>\n",
       "      <td>612</td>\n",
       "      <td>2507</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_20200131_110220.jpg</td>\n",
       "      <td>3968</td>\n",
       "      <td>2976</td>\n",
       "      <td>h</td>\n",
       "      <td>1468</td>\n",
       "      <td>659</td>\n",
       "      <td>1937</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DSC_0105.JPG</td>\n",
       "      <td>3000</td>\n",
       "      <td>4496</td>\n",
       "      <td>h</td>\n",
       "      <td>1371</td>\n",
       "      <td>597</td>\n",
       "      <td>1994</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>IMG_20200131_122719.jpg</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>j</td>\n",
       "      <td>854</td>\n",
       "      <td>1243</td>\n",
       "      <td>2248</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>IMG_20200131_122719.jpg</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>h</td>\n",
       "      <td>2285</td>\n",
       "      <td>1062</td>\n",
       "      <td>4129</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IMG_20200204_162040.jpg</td>\n",
       "      <td>3456</td>\n",
       "      <td>4608</td>\n",
       "      <td>j</td>\n",
       "      <td>928</td>\n",
       "      <td>575</td>\n",
       "      <td>2665</td>\n",
       "      <td>2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>IMG_20200204_162040.jpg</td>\n",
       "      <td>3456</td>\n",
       "      <td>4608</td>\n",
       "      <td>h</td>\n",
       "      <td>1815</td>\n",
       "      <td>2450</td>\n",
       "      <td>3397</td>\n",
       "      <td>4206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  width  height class  xmin  ymin  xmax  ymax\n",
       "0              DSC_0003.JPG   3000    4496     h  1024   297  2129  1515\n",
       "1              DSC_0114.JPG   4496    3000     j  2007   120  2513   685\n",
       "2   IMG_20200131_124203.jpg   3120    4160     h  1359  1349  1820  1782\n",
       "3   IMG_20200204_091655.jpg   4160    3120     j  1674   612  2507  1312\n",
       "4   IMG_20200131_110220.jpg   3968    2976     h  1468   659  1937  1169\n",
       "..                      ...    ...     ...   ...   ...   ...   ...   ...\n",
       "56             DSC_0105.JPG   3000    4496     h  1371   597  1994  1191\n",
       "57  IMG_20200131_122719.jpg   4608    3456     j   854  1243  2248  2655\n",
       "58  IMG_20200131_122719.jpg   4608    3456     h  2285  1062  4129  3018\n",
       "59  IMG_20200204_162040.jpg   3456    4608     j   928   575  2665  2169\n",
       "60  IMG_20200204_162040.jpg   3456    4608     h  1815  2450  3397  4206\n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do this twice: once for our training labels and once for our validation labels\n",
    "utils.xml_to_csv('/content/Data/peoples/train_labels', 'train.csv')\n",
    "utils.xml_to_csv('/content/Data/peoples/val_labels', 'val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csLF8GKQ3CGe"
   },
   "source": [
    "Below, we create our dataset, applying a couple of transforms beforehand. These are optional, but they can be useful for augmenting your dataset without gathering more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7j17jxf31Gk"
   },
   "outputs": [],
   "source": [
    "# Specify a list of transformations for our dataset to apply on our images\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(800),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform(),\n",
    "])\n",
    "\n",
    "dataset = core.Dataset('train.csv', '/content/Data/peoples/images/', transform=transform_img)\n",
    "\n",
    "# dataset[i] returns a tuple containing our transformed image and\n",
    "# and a dictionary containing label and box data\n",
    "image, target = dataset[4]\n",
    "\n",
    "# Show our image along with the box. Note: it may\n",
    "# be colored oddly due to being normalized by the \n",
    "# dataset and then reverse-normalized for plotting\n",
    "visualize.show_labeled_image(image, target['boxes'], target['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPFYk-lv6Cgd"
   },
   "source": [
    "Finally, let's train our model! First, we create a DataLoader over our dataset to specify how we feed the images into our model. We also use our validation dataset to track the accuracy of the model throughout training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLRHugVo6kAt"
   },
   "outputs": [],
   "source": [
    "# Create our validation dataset\n",
    "val_dataset = core.Dataset('val.csv', '/content/Data/peoples/images/')\n",
    "\n",
    "# Create the loader for our training dataset\n",
    "loader = core.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Create our model, passing in all unique classes we're predicting\n",
    "# Note: make sure these match exactly with the labels in the XML/CSV files!\n",
    "model = core.Model(['pen', 'mouse', 'remote'])\n",
    "\n",
    "# Train the model! This step can take a while, so make sure you\n",
    "# the GPU is turned on in Edit -> Notebook settings\n",
    "losses = model.fit(loader, val_dataset, epochs=10, verbose=True)\n",
    "\n",
    "# Plot the accuracy over time\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeRKZMNJ9cfc"
   },
   "source": [
    "Let's see how well our model does on a couple images from our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvHbAcLb9cIL"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "# Create a list of images 0, 5, 10, ... 40 from val_dataset\n",
    "for i in range(0, 45, 5):\n",
    "    image, _ = val_dataset[i]\n",
    "    images.append(image)\n",
    "\n",
    "# Plot a 3x3 grid of the model's predictions on our 9 images\n",
    "visualize.plot_prediction_grid(model, images, dim=(3, 3), figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5JOdATRBhIz"
   },
   "source": [
    "Overall, the model works as expected; in most of the images, it outputs high confidence values for the correct breed of dog shown. With a bit more fine-tuning, we could make it even better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDz1v5Lh-uZG"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Thanks for making it this far through the demo!\n",
    "\n",
    "This is as far as the demo goes, but a great next step would be seeing how well the model works on a live video of Chihuahuas and Golden Retrievers in the same frame at the same time. To learn more about Detecto, be sure to check out the [Quickstart guide](https://detecto.readthedocs.io/en/latest/usage/quickstart.html), [Further Usage guide](https://detecto.readthedocs.io/en/latest/usage/further-usage.html), and [API docs](https://detecto.readthedocs.io/en/latest/api.html)!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NID-Object Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
