{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjPddODfghiz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiilEphggiEv"
   },
   "source": [
    "# Open In Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1y8o1MugoPb"
   },
   "source": [
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Bg8MQnfRZpc2Wy52XEpqaBtsopmA0Hoc?authuser=1#scrollTo=gGnaQzjyhxhu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14gJOQFRtbmq"
   },
   "source": [
    "# Install & Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11351,
     "status": "ok",
     "timestamp": 1605372619281,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "gGnaQzjyhxhu",
    "outputId": "3d2431e7-2da6-42a1-f930-f1294b939c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading https://files.pythonhosted.org/packages/17/4b/4dbd55388225bb6cd243d21f70e77cb3ce061e241257485936324b8e920f/pytesseract-0.3.6.tar.gz\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
      "Building wheels for collected packages: pytesseract\n",
      "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytesseract: filename=pytesseract-0.3.6-py2.py3-none-any.whl size=13629 sha256=c5749ad581538dc26de7946ba0073467ae81282a1d571082465a69f7ae4cc560\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/71/72/b98430261d849ae631e283dfc7ccb456a3fb2ed2205714b63f\n",
      "Successfully built pytesseract\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.6\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
      "0 upgraded, 3 newly installed, 0 to remove and 12 not upgraded.\n",
      "Need to get 4,795 kB of archives.\n",
      "After this operation, 15.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
      "Fetched 4,795 kB in 2s (3,016 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "(Reading database ... 144786 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "# install easy-ocr module\n",
    "\n",
    "!pip install pytesseract\n",
    "!sudo apt install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1605372794342,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "WOxu3m1aq8gC",
    "outputId": "af90b5d1-2e61-4eec-9d7c-511f781b5687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required module\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, os\n",
    "from pylab import rcParams\n",
    "from IPython.display import Image\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt \n",
    "import pytesseract\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from PIL import ImageColor\n",
    "from datetime import datetime\n",
    "from imutils import paths\n",
    "import glob\n",
    "import re\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 8, 16\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-92u0pxuay-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3rmkHmftWFX"
   },
   "source": [
    "# Download Required File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3960,
     "status": "ok",
     "timestamp": 1605372666519,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "15zHapqw_8zn",
    "outputId": "ccd10d1d-f003-46fc-c79d-8012dd963664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-14 16:51:02--  https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99693937 (95M) [application/octet-stream]\n",
      "Saving to: ‘shape_predictor_68_face_landmarks.dat’\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  95.08M   162MB/s    in 0.6s    \n",
      "\n",
      "2020-11-14 16:51:04 (162 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n",
      "\n",
      "--2020-11-14 16:51:04--  https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96662756 (92M) [application/octet-stream]\n",
      "Saving to: ‘frozen_east_text_detection.pb’\n",
      "\n",
      "frozen_east_text_de 100%[===================>]  92.18M   170MB/s    in 0.5s    \n",
      "\n",
      "2020-11-14 16:51:06 (170 MB/s) - ‘frozen_east_text_detection.pb’ saved [96662756/96662756]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download file from github link\n",
    "# landmark.dat used for detection of facial landmarks detection as well face recognition\n",
    "# frozen_east_text_detection.pb for EAST deep learning model\n",
    "! wget https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
    "! wget https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CSw642QtamP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jjE7q6J2qE9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IarV7JZktQpD"
   },
   "source": [
    "# Making Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqs-2P-E8GUf"
   },
   "outputs": [],
   "source": [
    "# make a folder to store split text image from main image\n",
    "\n",
    "if os.path.exists('/content/east-cropedd'):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('/content/east-cropedd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elILL7nOtn1R"
   },
   "source": [
    "# Dataset Making - Implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-49Ik5xOpTd3"
   },
   "outputs": [],
   "source": [
    "def EAST_DATASET():\n",
    "\n",
    "    args = {\n",
    "    # \"image\" : \"/home/alpha/Desktop/opencv-text-detection/images/car_wash.png\",\n",
    "    \"image\" : '/content/NID_cropped.png',\n",
    "    \"east\" : '/content/frozen_east_text_detection.pb',\n",
    "    \"min_confidence\" : 0.5,\n",
    "    \"width\" : 320,\n",
    "    \"height\" : 320\n",
    "\n",
    "    }\n",
    "\n",
    "    # load the input image and grab the image dimensions\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    orig = image.copy()\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height\n",
    "    (newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # define the two output layer names for the EAST detector model that\n",
    "    # we are interested -- the first is the output probabilities and the\n",
    "    # second can be used to derive the bounding box coordinates of text\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "\n",
    "    # load the pre-trained EAST text detector\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    net = cv2.dnn.readNet(args[\"east\"])\n",
    "\n",
    "    # construct a blob from the image and then perform a forward pass of\n",
    "    # the model to obtain the two output layer sets\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "        (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    start = time.time()\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    end = time.time()\n",
    "\n",
    "    # show timing information on text prediction\n",
    "    print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability, ignore it\n",
    "            if scoresData[x] < args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "    # boxes\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    img_no = 1\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "\n",
    "        # draw the bounding box on the image\n",
    "        #cv2.rectangle(orig, (startX-5, startY-5), (endX+10, endY+10), (0, 255, 0), 2)\n",
    "        try:\n",
    "            img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "            roi = orig[startY-10:endY+15, startX-15:endX+145]\n",
    "            cv2.imwrite(img_name, roi)\n",
    "\n",
    "            img_no = img_no + 1\n",
    "        except:\n",
    "            try:\n",
    "                img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "                roi = orig[startY-10:endY+10, startX-5:endX+130]\n",
    "                cv2.imwrite(img_name, roi)\n",
    "\n",
    "                img_no = img_no + 1\n",
    "            except:\n",
    "                img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "                roi = orig[startY-5:endY+10, startX-5:endX+130]\n",
    "                cv2.imwrite(img_name, roi)\n",
    "\n",
    "                img_no = img_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjVNFRVZ8SZV"
   },
   "outputs": [],
   "source": [
    "# instantiate dlib for face frontal detection land marks detection\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def make_dataset(img_path, isDelete=True):\n",
    "\n",
    "    # delete the pre-load images from this folder\n",
    "    if isDelete:\n",
    "        files = glob.glob('/content/east-cropedd/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "            \n",
    "    # load image and resize for further used\n",
    "    filename = img_path\n",
    "    img = cv2.imread(cv2.samples.findFile(filename)) # read image   \n",
    "    img = cv2.resize(img, (640, 480))  # resize image\n",
    "\n",
    "    imgOriginal = img.copy() # make a copy the original image\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert image into grayscale\n",
    "\n",
    "    # detect faces from image and its corresponding x-axis and y-axis location\n",
    "    # cropped face from image according to x and y location\n",
    "    faces = detector(imgOriginal)  # detect all faces region \n",
    "    for face in faces:\n",
    "        x1,y1 = face.left(),face.top() \n",
    "        x2,y2 = face.right(),face.bottom()\n",
    "\n",
    "        # cropped image\n",
    "        cropped = imgOriginal[y1-25:y2+150 , x2+10:x2 + 320]\n",
    "\n",
    "        # saved the croped image\n",
    "        cv2.imwrite(\"NID_cropped.png\", cropped)\n",
    "    \n",
    "\n",
    "    # Dataset for EAST model\n",
    "    EAST_DATASET()\n",
    "    # End Dataset function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myAE0Q8v8SMj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1rl8gXUGtmt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO4cjuBzuuMM"
   },
   "source": [
    "# EAST Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBu3HPoxqh43"
   },
   "outputs": [],
   "source": [
    "# Month name\n",
    "MONTH_NAME = ['Jan', 'Feb', 'Apr' 'Mar', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# this function used to extract NID no from text\n",
    "def EAST_extract_digit(sent, n_digit):\n",
    "    sent = sent.strip()\n",
    "    nmb_list = [s for s in sent.split() if s.isdigit()]\n",
    "    nmb = \"\".join(nmb_list)\n",
    "    nmb_list, nmb, len(nmb)\n",
    "\n",
    "    if len(nmb) > n_digit:\n",
    "        return nmb\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# this function used to extract age from text\n",
    "def EAST_extract_age(sent):\n",
    "    sent =  sent.strip()\n",
    "    word_token = nltk.tokenize.word_tokenize(sent)\n",
    "    for i, word in enumerate(word_token):\n",
    "        try:\n",
    "            if word in MONTH_NAME:\n",
    "                date_c = word_token[i-1]\n",
    "                s_d = re.search(r\"\\d+(\\.\\d+)?\", date_c)\n",
    "                date = s_d.group(0)\n",
    "\n",
    "                month = word_token[i]\n",
    "\n",
    "\n",
    "                year_c = word_token[i+1]\n",
    "                y_d = re.search(r\"\\d+(\\.\\d+)?\", year_c)\n",
    "                year = y_d.group(0)\n",
    "\n",
    "                if len(date) == 2 and len(year) == 4 and int(date) < 32:\n",
    "                    b_date = date + \" \" + month + \" \" + year\n",
    "                    # print(b_date)\n",
    "                    return b_date\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# this function used to extract name from text           \n",
    "def EAST_extract_name(sent):\n",
    "    sent =  sent.strip()\n",
    "    upper_res = [char for char in sent if char.isupper()]\n",
    "    if len(upper_res) > 8 and sent[0].isupper() and sent[1].isupper() and sent[-2].isupper() and sent[-1].isupper():\n",
    "        #print(\"*********************************************************\")\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bjT2x7oqh8E"
   },
   "outputs": [],
   "source": [
    "# This function used to extract information: Name, Age, NID number\n",
    "# as well as all text detect by OCR engine\n",
    "\n",
    "ef Extract_NID_INFO_EAST_OCR():\n",
    "\n",
    "    IMG_DIR = '/content/east-cropedd'\n",
    "    \n",
    "    sent_list =  list()\n",
    "    name =\"Not Found\"\n",
    "    age =\"Not Found\"\n",
    "    NID_NUM =\"Not Found\"\n",
    "    for img_name in os.listdir(IMG_DIR):\n",
    "        img_path = IMG_DIR + \"/\" +img_name\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        sent = pytesseract.image_to_string(rgb)\n",
    "\n",
    "        NID_extract = EAST_extract_digit(sent, 5)\n",
    "        age_extract = EAST_extract_age(sent)\n",
    "        name_extact = EAST_extract_name(sent)\n",
    "\n",
    "        if NID_extract != None and len(NID_extract) == 10:\n",
    "            NID_NUM = NID_extract\n",
    "        if age_extract != None:\n",
    "            age = age_extract\n",
    "        if name_extact != None:\n",
    "            name = name_extact\n",
    "        \n",
    "        sent_list.append(sent)\n",
    "            \n",
    "    info_dict = dict()\n",
    "    info_dict[\"Name\"] = name\n",
    "    info_dict[\"Date of Birth\"] = age\n",
    "    info_dict[\"NID_no\"] = NID_NUM\n",
    "\n",
    "    return info_dict, sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgeEkbB9qh11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV5e4iFjp0HS"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Making Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2012,
     "status": "ok",
     "timestamp": 1605372948812,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "xeIFHSo4rgb3",
    "outputId": "5028fb56-32fc-432b-ba2b-55f90cefdd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n",
      "[INFO] text detection took 0.607038 seconds\n"
     ]
    }
   ],
   "source": [
    "# make dataset for OCR\n",
    "make_dataset('/content/111.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAttPQE-BwN1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFrL8e6jvtsd"
   },
   "source": [
    "# EAST (OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3539,
     "status": "ok",
     "timestamp": 1605373492482,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "Dj_HBvoPBwHr",
    "outputId": "d6ec96ab-4a30-4958-fd58-25800dac69e0"
   },
   "outputs": [],
   "source": [
    "#print information: Name, Age, NID number\n",
    "info_east_ocr, all_info = Extract_NID_INFO_EAST_OCR()\n",
    "print(\"*\"*50)\n",
    "print(info_east_ocr)\n",
    "print(\"*\"*50)\n",
    "\n",
    "# print all text detected by OCR engine\n",
    "print(\"\\n\\n\")\n",
    "print(\"*\"*50)\n",
    "print(\"Extracted text by OCR Engine(below) : \")\n",
    "for sent in all_info:\n",
    "    print(sent.strip())\n",
    "print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZtFDaeqBwCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4MiNCQEBv4K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3woQqu45Bvyu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EAST-OCR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
