{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdcQxM8ejxua"
   },
   "source": [
    "# Open In Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuVwaFVujzFG"
   },
   "source": [
    "### Open this notebook in google colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Bg8MQnfRZpc2Wy52XEpqaBtsopmA0Hoc?authuser=1#scrollTo=gGnaQzjyhxhu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14gJOQFRtbmq"
   },
   "source": [
    "# Install & Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19827,
     "status": "ok",
     "timestamp": 1605276520589,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "gGnaQzjyhxhu",
    "outputId": "5cda0c13-5da4-4be9-be71-6b6cf0f794c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading https://files.pythonhosted.org/packages/17/4b/4dbd55388225bb6cd243d21f70e77cb3ce061e241257485936324b8e920f/pytesseract-0.3.6.tar.gz\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
      "Building wheels for collected packages: pytesseract\n",
      "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytesseract: filename=pytesseract-0.3.6-py2.py3-none-any.whl size=13629 sha256=2b0706a299deae8a4c2225045589626c9777dd3b142297b852c603fd8caaf894\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/71/72/b98430261d849ae631e283dfc7ccb456a3fb2ed2205714b63f\n",
      "Successfully built pytesseract\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.6\n",
      "Collecting easyocr\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/49/c0bc96969a7f8167fb0478e50ad3f5ad2c6d93c99e20dc82875e92e0d783/easyocr-1.1.10-py3-none-any.whl (48.9MB)\n",
      "\u001b[K     |████████████████████████████████| 48.9MB 59kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from easyocr) (1.18.5)\n",
      "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from easyocr) (0.8.1+cu101)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from easyocr) (4.1.2.30)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from easyocr) (1.4.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from easyocr) (0.16.2)\n",
      "Collecting python-bidi\n",
      "  Downloading https://files.pythonhosted.org/packages/33/b0/f942d146a2f457233baaafd6bdf624eba8e0f665045b4abd69d1b62d097d/python_bidi-0.4.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from easyocr) (7.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from easyocr) (1.7.0+cu101)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->easyocr) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->easyocr) (2.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->easyocr) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->easyocr) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->easyocr) (0.7)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->easyocr) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.1)\n",
      "Installing collected packages: python-bidi, easyocr\n",
      "Successfully installed easyocr-1.1.10 python-bidi-0.4.2\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
      "0 upgraded, 3 newly installed, 0 to remove and 12 not upgraded.\n",
      "Need to get 4,795 kB of archives.\n",
      "After this operation, 15.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
      "Fetched 4,795 kB in 1s (5,349 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "(Reading database ... 144786 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
      "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n",
    "! pip install easyocr\n",
    "!sudo apt install tesseract-ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5fDEa8rfxVM"
   },
   "outputs": [],
   "source": [
    "# ! sudo apt-get update\n",
    "# !sudo apt-get install libleptonica-dev \n",
    "# ! sudo apt-get install tesseract-ocr tesseract-ocr-dev\n",
    "# ! sudo apt-get install libtesseract-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28450,
     "status": "ok",
     "timestamp": 1605276529229,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "WOxu3m1aq8gC",
    "outputId": "5e7028a4-8ac3-472d-cddb-5f41da820260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2, os\n",
    "import easyocr\n",
    "from pylab import rcParams\n",
    "from IPython.display import Image\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt \n",
    "import pytesseract\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from PIL import ImageColor\n",
    "from datetime import datetime\n",
    "from imutils import paths\n",
    "import glob\n",
    "import re\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 8, 16\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55070,
     "status": "ok",
     "timestamp": 1605276555852,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "K39DhEUk_RqU",
    "outputId": "ee2cf5a1-7635-4daa-cd68-33ec93ebce83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "en_reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-92u0pxuay-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3rmkHmftWFX"
   },
   "source": [
    "# Download Required File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57946,
     "status": "ok",
     "timestamp": 1605276558742,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "15zHapqw_8zn",
    "outputId": "d613ac1a-afb3-4da6-d33d-cb8bddafa9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-13 14:09:13--  https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99693937 (95M) [application/octet-stream]\n",
      "Saving to: ‘shape_predictor_68_face_landmarks.dat’\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  95.08M   325MB/s    in 0.3s    \n",
      "\n",
      "2020-11-13 14:09:15 (325 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n",
      "\n",
      "--2020-11-13 14:09:15--  https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96662756 (92M) [application/octet-stream]\n",
      "Saving to: ‘frozen_east_text_detection.pb’\n",
      "\n",
      "frozen_east_text_de 100%[===================>]  92.18M   238MB/s    in 0.4s    \n",
      "\n",
      "2020-11-13 14:09:16 (238 MB/s) - ‘frozen_east_text_detection.pb’ saved [96662756/96662756]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/AKSHAYUBHAT/TensorFace/master/openface/models/dlib/shape_predictor_68_face_landmarks.dat\n",
    "! wget https://raw.githubusercontent.com/oyyd/frozen_east_text_detection.pb/master/frozen_east_text_detection.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CSw642QtamP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jjE7q6J2qE9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IarV7JZktQpD"
   },
   "source": [
    "# Making Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqs-2P-E8GUf"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/content/manual-cropedd'):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('/content/manual-cropedd')\n",
    "\n",
    "\n",
    "if os.path.exists('/content/east-cropedd'):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('/content/east-cropedd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elILL7nOtn1R"
   },
   "source": [
    "# Dataset Making - Implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-49Ik5xOpTd3"
   },
   "outputs": [],
   "source": [
    "def EAST_DATASET():\n",
    "\n",
    "    args = {\n",
    "    # \"image\" : \"/home/alpha/Desktop/opencv-text-detection/images/car_wash.png\",\n",
    "    \"image\" : '/content/NID_cropped.png',\n",
    "    \"east\" : '/content/frozen_east_text_detection.pb',\n",
    "    \"min_confidence\" : 0.5,\n",
    "    \"width\" : 320,\n",
    "    \"height\" : 320\n",
    "\n",
    "    }\n",
    "\n",
    "    # load the input image and grab the image dimensions\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    orig = image.copy()\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height\n",
    "    (newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # define the two output layer names for the EAST detector model that\n",
    "    # we are interested -- the first is the output probabilities and the\n",
    "    # second can be used to derive the bounding box coordinates of text\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "\n",
    "    # load the pre-trained EAST text detector\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    net = cv2.dnn.readNet(args[\"east\"])\n",
    "\n",
    "    # construct a blob from the image and then perform a forward pass of\n",
    "    # the model to obtain the two output layer sets\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "        (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    start = time.time()\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    end = time.time()\n",
    "\n",
    "    # show timing information on text prediction\n",
    "    print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability, ignore it\n",
    "            if scoresData[x] < args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "    # boxes\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    img_no = 1\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "\n",
    "        # draw the bounding box on the image\n",
    "        #cv2.rectangle(orig, (startX-5, startY-5), (endX+10, endY+10), (0, 255, 0), 2)\n",
    "        try:\n",
    "            img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "            roi = orig[startY-10:endY+15, startX-15:endX+145]\n",
    "            cv2.imwrite(img_name, roi)\n",
    "\n",
    "            img_no = img_no + 1\n",
    "        except:\n",
    "            try:\n",
    "                img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "                roi = orig[startY-10:endY+10, startX-5:endX+130]\n",
    "                cv2.imwrite(img_name, roi)\n",
    "\n",
    "                img_no = img_no + 1\n",
    "            except:\n",
    "                img_name = \"/content/east-cropedd/\"+str(img_no)+\".png\"\n",
    "                roi = orig[startY-5:endY+10, startX-5:endX+130]\n",
    "                cv2.imwrite(img_name, roi)\n",
    "\n",
    "                img_no = img_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjVNFRVZ8SZV"
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def make_dataset(img_path, isDelete=True):\n",
    "\n",
    "    if isDelete:\n",
    "        files = glob.glob('/content/manual-cropedd/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        files = glob.glob('/content/east-cropedd/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "    # extrction information part from croped image based face\n",
    "    filename = img_path\n",
    "    img = cv2.imread(cv2.samples.findFile(filename))\n",
    "    img = cv2.resize(img, (640, 480))\n",
    "\n",
    "    imgOriginal = img.copy()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(imgOriginal)\n",
    "    for face in faces:\n",
    "        x1,y1 = face.left(),face.top()\n",
    "        x2,y2 = face.right(),face.bottom()\n",
    "\n",
    "\n",
    "        cropped = imgOriginal[y1-25:y2+150 , x2+10:x2 + 320]\n",
    "\n",
    "        cv2.imwrite(\"NID_cropped.png\", cropped)\n",
    "    \n",
    "        # cropped each infromation and saved it in a directory\n",
    "        img = cropped\n",
    "        x_val, y_val, c = img.shape\n",
    "\n",
    "        x , y = 0, 0\n",
    "        for i in range(y_val):\n",
    "            x = 0\n",
    "            y = y + 10\n",
    "            w, h = y_val, 60\n",
    "\n",
    "\n",
    "            if y+10 > y_val:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                crop_img = img[y:y+h, x:x+w]\n",
    "                img_name = \"/content/manual-cropedd/\"+str(i)+\".jpg\"\n",
    "                cv2.imwrite(img_name, crop_img)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Dataset for EAST model\n",
    "    EAST_DATASET()\n",
    "    # End Dataset function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myAE0Q8v8SMj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VA1AKrUc_Wzf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKmSie-VszDg"
   },
   "source": [
    "# Easy-OCR Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbFTvo-Ys3nb"
   },
   "source": [
    "### Requeired function - Easy OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFceePJoh8tW"
   },
   "outputs": [],
   "source": [
    "\n",
    "MONTH_NAME = ['Jan', 'Feb', 'Apr' 'Mar', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "\n",
    "\n",
    "def EASY_month_matching(sent):\n",
    "    sent =  sent.strip()\n",
    "    word_token = nltk.tokenize.word_tokenize(sent)\n",
    "    for i, word in enumerate(word_token):\n",
    "        if word in MONTH_NAME:\n",
    "            date_c = word_token[i-1]\n",
    "            s_d = re.search(r\"\\d+(\\.\\d+)?\", date_c)\n",
    "            date = s_d.group(0)\n",
    "\n",
    "            month = word_token[i]\n",
    "\n",
    "\n",
    "            year = word_token[i+1]\n",
    "            \n",
    "\n",
    "            b_date = date + \" \" + month + \" \" + year\n",
    "            # print(b_date)\n",
    "            return b_date\n",
    "\n",
    "def EASY_NID_matching(sent):\n",
    "    sent =  sent.strip()\n",
    "    word_token = nltk.tokenize.word_tokenize(sent)\n",
    "    for i, word in enumerate(word_token):\n",
    "        try:\n",
    "            if word_token[i].isdigit() and word_token[i+1].isdigit() and word_token[i+2].isdigit():\n",
    "                if len(word_token[i]) >= 3 and len(word_token[i+1]) >= 3 and len(word_token[i+1]) >= 3 :\n",
    "                    NID_no = word_token[i] +\" \" + word_token[i+1] +\" \" +  word_token[i+2]\n",
    "                    return NID_no\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxUlgEwTtB_V"
   },
   "source": [
    "### Info extraction functon  - Easy OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6E3k86QH_Zh"
   },
   "outputs": [],
   "source": [
    "def Extract_NID_INFO_EASY_OCR(img_path):\n",
    "    \n",
    "    img = plt.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    name = 'Not Found'\n",
    "    birthday = 'Not Found'\n",
    "    NID_number = 'Not Found'\n",
    "    info_dict = dict()\n",
    "    en_output = en_reader.readtext(img_path)\n",
    "    for out in en_output:\n",
    "        sent = out[1]\n",
    "        res = [char for char in sent if char.isupper()]\n",
    "        if len(res) > 6:\n",
    "            name = sent\n",
    "        \n",
    "        b_date = EASY_month_matching(sent)\n",
    "        NID_no = EASY_NID_matching(sent)\n",
    "        if b_date != None:\n",
    "            birthday = b_date\n",
    "        if NID_no != None:\n",
    "            NID_number = NID_no\n",
    "            \n",
    "\n",
    "\n",
    "    info_dict[\"Name\"] = name\n",
    "    info_dict[\"Date of Birth\"] = birthday\n",
    "    info_dict[\"NID_no\"] = NID_number\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7V46LwjspHo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wjf4BPKgspA6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRN2vYU2spZ5"
   },
   "source": [
    "# PYTESSEROCR Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6oS6GG0Gt1g"
   },
   "outputs": [],
   "source": [
    "def PYTESS_OCR_month_matching(sent):\n",
    "    sent =  sent.strip()\n",
    "    word_token = nltk.tokenize.word_tokenize(sent)\n",
    "    for i, word in enumerate(word_token):\n",
    "        if word in MONTH_NAME:\n",
    "            date = word_token[i-1]\n",
    "\n",
    "            month = word_token[i]\n",
    "\n",
    "\n",
    "            year = word_token[i+1]\n",
    "            \n",
    "\n",
    "            b_date = date + \" \" + month + \" \" + year\n",
    "            # print(b_date)\n",
    "            return b_date\n",
    "\n",
    "def PYTESS_extract_digit(sent):\n",
    "    nmb_list = [s for s in sent.split() if s.isdigit()]\n",
    "    nmb = \"\".join(nmb_list)\n",
    "    nmb_list, nmb, len(nmb)\n",
    "\n",
    "    if len(nmb) > 8:\n",
    "        return nmb\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def PYTESS_name_check(sent):\n",
    "    sent =  sent.strip()\n",
    "    upper_res = [char for char in sent if char.isupper()]\n",
    "    if len(upper_res) > 6 and sent[0].isupper() and sent[1].isupper() and sent[-2].isupper() and sent[-1].isupper():\n",
    "        #print(\"*********************************************************\")\n",
    "        return \"ok\"\n",
    "    else:\n",
    "        return \"notok\"\n",
    "\n",
    "def Extract_NID_INFO_PYTESS_OCR():\n",
    "    IMG_DIR = '/content/manual-cropedd'\n",
    "\n",
    "    name =\"Not Found\"\n",
    "    age =\"Not Found\"\n",
    "    NID_NUM =\"Not Found\"\n",
    "    for img_name in os.listdir(IMG_DIR):\n",
    "        img_path = IMG_DIR + \"/\" +img_name\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        sent = pytesseract.image_to_string(rgb)\n",
    "        \n",
    "        name_status = PYTESS_name_check(sent)\n",
    "            \n",
    "        b_date = PYTESS_OCR_month_matching(sent)\n",
    "        NID_no = PYTESS_extract_digit(sent)\n",
    "        \n",
    "        #print(\"=============> \", sent)\n",
    "        if name_status == \"ok\":\n",
    "            name = sent\n",
    "            # print(sent)\n",
    "        if b_date != None:\n",
    "            age = b_date\n",
    "            # print(b_date)\n",
    "        if NID_no != None and len(NID_no) == 10:\n",
    "            NID_NUM = NID_no\n",
    "            # print(NID_NUM)\n",
    "        \n",
    "    info_dict = dict()\n",
    "    info_dict[\"Name\"] = name.strip()\n",
    "    info_dict[\"Date of Birth\"] = age\n",
    "    info_dict[\"NID_no\"] = NID_NUM\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1rl8gXUGtmt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO4cjuBzuuMM"
   },
   "source": [
    "# EAST Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBu3HPoxqh43"
   },
   "outputs": [],
   "source": [
    "def EAST_extract_digit(sent, n_digit):\n",
    "    sent = sent.strip()\n",
    "    nmb_list = [s for s in sent.split() if s.isdigit()]\n",
    "    nmb = \"\".join(nmb_list)\n",
    "    nmb_list, nmb, len(nmb)\n",
    "\n",
    "    if len(nmb) > n_digit:\n",
    "        return nmb\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "MONTH_NAME = ['Jan', 'Feb', 'Apr' 'Mar', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "def EAST_extract_age(sent):\n",
    "    sent =  sent.strip()\n",
    "    word_token = nltk.tokenize.word_tokenize(sent)\n",
    "    for i, word in enumerate(word_token):\n",
    "        try:\n",
    "            if word in MONTH_NAME:\n",
    "                date_c = word_token[i-1]\n",
    "                s_d = re.search(r\"\\d+(\\.\\d+)?\", date_c)\n",
    "                date = s_d.group(0)\n",
    "\n",
    "                month = word_token[i]\n",
    "\n",
    "\n",
    "                year_c = word_token[i+1]\n",
    "                y_d = re.search(r\"\\d+(\\.\\d+)?\", year_c)\n",
    "                year = y_d.group(0)\n",
    "\n",
    "                if len(date) == 2 and len(year) == 4 and int(date) < 32:\n",
    "                    b_date = date + \" \" + month + \" \" + year\n",
    "                    # print(b_date)\n",
    "                    return b_date\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "def EAST_extract_name(sent):\n",
    "    sent =  sent.strip()\n",
    "    upper_res = [char for char in sent if char.isupper()]\n",
    "    if len(upper_res) > 6 and sent[0].isupper() and sent[1].isupper() and sent[-2].isupper() and sent[-1].isupper():\n",
    "        #print(\"*********************************************************\")\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bjT2x7oqh8E"
   },
   "outputs": [],
   "source": [
    "def Extract_NID_INFO_EAST_OCR():\n",
    "\n",
    "    IMG_DIR = '/content/east-cropedd'\n",
    "    \n",
    "    name =\"Not Found\"\n",
    "    age =\"Not Found\"\n",
    "    NID_NUM =\"Not Found\"\n",
    "    for img_name in os.listdir(IMG_DIR):\n",
    "        img_path = IMG_DIR + \"/\" +img_name\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        sent = pytesseract.image_to_string(rgb)\n",
    "\n",
    "        NID_extract = EAST_extract_digit(sent, 5)\n",
    "        age_extract = EAST_extract_age(sent)\n",
    "        name_extact = EAST_extract_name(sent)\n",
    "\n",
    "        if NID_extract != None and len(NID_extract) == 10:\n",
    "            NID_NUM = NID_extract\n",
    "        if age_extract != None:\n",
    "            age = age_extract\n",
    "        if name_extact != None:\n",
    "            name = name_extact\n",
    "            \n",
    "    info_dict = dict()\n",
    "    info_dict[\"Name\"] = name\n",
    "    info_dict[\"Date of Birth\"] = age\n",
    "    info_dict[\"NID_no\"] = NID_NUM\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgeEkbB9qh11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV5e4iFjp0HS"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Making Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2260,
     "status": "ok",
     "timestamp": 1605278153542,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "xeIFHSo4rgb3",
    "outputId": "222d302e-7bb6-469f-ec52-251c96f5ca38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n",
      "[INFO] text detection took 0.590706 seconds\n"
     ]
    }
   ],
   "source": [
    "make_dataset('/content/111.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKDO-wdrp8fc"
   },
   "source": [
    "### EASY OCR (OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 67885,
     "status": "ok",
     "timestamp": 1605276568723,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "bAYO77fLpzO_",
    "outputId": "72649166-2952-497e-d59b-67ff17ea3b36"
   },
   "outputs": [],
   "source": [
    "info_easy_ocr = Extract_NID_INFO_EASY_OCR('/content/NID_cropped.png')\n",
    "print(info_easy_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_asVy4sKqDzr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gay8uVkiqEfi"
   },
   "source": [
    "### Tesseract-OCR (OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68805,
     "status": "ok",
     "timestamp": 1605276569652,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "I8AaVEuIyIWd",
    "outputId": "d35509b4-bf1f-47b1-ed24-4ea06a244044"
   },
   "outputs": [],
   "source": [
    "info_tess_ocr = Extract_NID_INFO_PYTESS_OCR()\n",
    "print(info_tess_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAttPQE-BwN1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFrL8e6jvtsd"
   },
   "source": [
    "# EAST (OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71453,
     "status": "ok",
     "timestamp": 1605276572307,
     "user": {
      "displayName": "jahid hasan",
      "photoUrl": "",
      "userId": "04583282639345967723"
     },
     "user_tz": -360
    },
    "id": "Dj_HBvoPBwHr",
    "outputId": "2ffc4b19-a19e-480b-cccb-26e6867b08d1"
   },
   "outputs": [],
   "source": [
    "info_east_ocr = Extract_NID_INFO_EAST_OCR()\n",
    "print(info_east_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZtFDaeqBwCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4MiNCQEBv4K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3woQqu45Bvyu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Three In One.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
